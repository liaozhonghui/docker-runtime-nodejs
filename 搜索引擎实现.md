数据结构与算法

1. 实际软件开发中如何使用数据结构和算法
   六条经验：
1. 时间，空间复杂度不能和性能简单的划等号
1. 抛开数据规模谈数据结构和算法都是“耍流氓”
1. 结合数据特征和访问方式来选择数据结构
1. 需要区别对待 IO 密集，内存密集（如字符串比较操作，解决方式：减少数据的读取量，看数据是否在内存中连续存储），和计算密集（使用位运算）
1. 善用语言提供的类，避免重复造轮子
1. 千万不要漫无目的的过渡优化（估算数据规模，性能压力进行估算，在真正优化代码的时候，一定要先做 benchmark 基准测试）

1. 实战篇- 开源项目、基础架构和中间件中都用了哪些数据结构和算法？
   具体分析：
1. redis 数据库

- 字符串
- 列表 （压缩列表，双向循环链表）单个数据不能超过 64 个字节，数据个数不能超过 512 个节点，压缩列表使用一段连续的内存空间
- 字典 （压缩列表，散列表） hash 冲突使用了链表法解决，扩容和缩容使用了渐进式 hash 策略
- 集合 （有序数组， 散列表)
- 有序集合 （压缩链表， 跳表）所有元素大小小于 64 字节，元素个数要小于 128 个
- 如何将数据结构进行持久化到磁盘呢？ rdb 和 aof 进行持久化
  （1. 清除原来的存储格式，使用格式化的方式进行存储，容易保存，2. 保留原来的存储格式存储，容易恢复）

2. 搜索引擎

- 如果通过少量的代码来实现一个小型的搜索引擎？
  8G 100GB
- 搜集，分析，索引，查询
  逻辑顺序：负责网页内容抽取，分词，构建临时索引，计算 pagerank 值。索引，主要通过分析阶段得到的临时索引，构建倒排索引。
  查询，主要负责响应用户的请求根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户。
- 搜集阶段：有向图，搜索引擎使用的是广度优先搜索策略 1. 待爬取网页链接文件 links.bin，将网页看做是一个大的字符串，然后字符串匹配算法，在这个大的字符串中，搜索<link>这样一个网页标签，然后顺序读取<link></link>之间的字符串。2. 网页判重文件，bloom_filter.bin 使用布隆过滤器进行过滤，节省内存，定期将布隆过滤器持久化到磁盘中。3.原始网页存储文件，doc_raw.bin 文件，一个文件中存储多个网页，限制每个文件大小为 1GB 即可。4. 网页链接及其对应编号的对应文件 doc_id.bin
- 分析阶段：离线分析， 抽取网页文本信息，分词并创建临时索引， 使用 ac 自动机查找 script option style，将标签中的内容进行连带删除，接着去掉所有 HTML 标签。 分词并创建临时索引，英文分析，中文分词，使用词库进行匹配。将词库中的单词创建成一个 trie 树，然后拿网页文本在 trie 树中进行匹配，然后得到一个单词列表，单词编号跟网页的对应关系保存为临时索引文件 temp_index.html，将单词跟编号之间的关系保存为单词编号文件 term_id.bin.
- 索引阶段：构建成倒排索引，使用多路归并排序，在实际软件开发中，可以直接利用 MapReduce 进行处理, 倒排索引文件，还有记录单词编号在索引文件中的偏移位置的文件。index.bin 和 term_offset.bin 文件
- 查询阶段：用户搜索功能
